dataset: "nuscenes"
data_root: "${oc.env:NUSCENES_ROOT,/data/nuscenes}"  # Environment variable with fallback
version: "v1.0-mini"  # Start with mini for testing
split: "train"
batch_size: 8  # Smaller for real data
num_workers: 4

# Data dimensions
image_size: [224, 224]
num_points: 1024
radar_size: [64, 64]

# Preprocessing
normalize_images: true
imagenet_mean: [0.485, 0.456, 0.406]
imagenet_std: [0.229, 0.224, 0.225]

# Augmentation
augmentation:
  enabled: true
  random_crop: true
  color_jitter: true
  horizontal_flip: false  # Don't flip autonomous driving scenes

# Action extraction
strategic_action_classes: 10  # Match action_encoder config
tactical_action_dim: 3  # [steering, acceleration, velocity]
action_normalization: true

# Sensor selection
cameras: ["CAM_FRONT"]  # Start with front camera only
lidar_sensors: ["LIDAR_TOP"]
radar_sensors: ["RADAR_FRONT"]

# Temporal sequence settings (for JEPA)
temporal:
  enabled: false  # Enable with data.temporal.enabled=true
  seq_length: 5  # Number of context frames (past)
  pred_horizon: 3  # Number of future frames to predict
  frame_skip: 1  # Use every Nth frame (1 = all frames, 2 = half)
  min_scene_length: 10  # Skip scenes with fewer samples
